{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Kaggle: Favorita Grocery Sales Forecasting<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Descripción\" data-toc-modified-id=\"Descripción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Descripción</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Imports</a></span></li><li><span><a href=\"#Lectura-de-datos\" data-toc-modified-id=\"Lectura-de-datos-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Lectura de datos</a></span></li><li><span><a href=\"#Carga-y-preprocesado\" data-toc-modified-id=\"Carga-y-preprocesado-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Carga y preprocesado</a></span></li><li><span><a href=\"#Muestras-de-entrenamiento-y-validación\" data-toc-modified-id=\"Muestras-de-entrenamiento-y-validación-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Muestras de entrenamiento y validación</a></span></li><li><span><a href=\"#Entrenamiento-y-validación-del-modelo\" data-toc-modified-id=\"Entrenamiento-y-validación-del-modelo-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Entrenamiento y validación del modelo</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notebook para jugar con los datos de la competición de Kaggle [favorita-grocery-sales-forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripción\n",
    "\n",
    "\"El objetivo del concurso es predecir las unidades vendidas de cada producto en una cadena de tiendas, por sede y fecha, durante las 2 semanas posteriores a los datos de entrenamiento.\"\n",
    "\n",
    "* Descargas + Información completa sobre los datasets: https://www.kaggle.com/c/favorita-grocery-sales-forecasting/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos\n",
    "\n",
    "Lo primero que hacemos antes de cargar el dataset, es ver qué contiene el fichero csv. Como hemos visto que es enorme (4,65GB) nos conviene optimizar el tamaño del dataframe, para lo que tendremos que ver qué columnas existen, sus tipos, y una muestra de los datos.\n",
    "\n",
    "Hay varias formas de indagar lo que tiene el fichero csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,date,store_nbr,item_nbr,unit_sales,onpromotion\n",
      "0,2013-01-01,25,103665,7.0,\n",
      "1,2013-01-01,25,105574,1.0,\n",
      "2,2013-01-01,25,105575,2.0,\n",
      "3,2013-01-01,25,108079,1.0,\n"
     ]
    }
   ],
   "source": [
    "!head -5 data/train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125497035,2017-08-15,54,2089339,4.0,False\n",
      "125497036,2017-08-15,54,2106464,1.0,True\n",
      "125497037,2017-08-15,54,2110456,192.0,False\n",
      "125497038,2017-08-15,54,2113914,198.0,True\n",
      "125497039,2017-08-15,54,2116416,2.0,False\n"
     ]
    }
   ],
   "source": [
    "!tail -5 data/train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vistos los datos, decidimos en qué tipo específico se puede encajar cada columna numérica, de forma que se ahorre espacio en memoria (Pandas no lo hace):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id': 'int32',\n",
    "         'store_nbr': 'int8',\n",
    "         'item_nbr': 'int32',\n",
    "         'unit_sales': 'float32',\n",
    "         'onpromotion': 'object'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga y preprocesado\n",
    "\n",
    "Para poder realizar el preprocesado tenemos el hándicap de que no podemos hacerlo con el dataset completo de la forma habitual, ya que tendremos problemas de memoria con un PC de 16GB de RAM.\n",
    "Existen varios enfoques:\n",
    " * Usar más RAM :P\n",
    " * Dividir los datos en chunks, hacer el preprocesado, y concatenar\n",
    " * Trabajar sólo con una parte del dataset original como primera táctica. Elegimos esta porque nos ahorra mucho tiempo de pruebas.\n",
    "\n",
    "Nota: Aplicaremos la función `log1p` de Numpy a la variable dependiente, ya que Kaggle especifica que medirá el NWRMSLE:\n",
    "\n",
    "![img/nwrmsle.png](img/nwrmsle.png)\n",
    "\n",
    "Primero escribimos algunas funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    '''\n",
    "    Función que se encarga de preprocesar los datos de entrada\n",
    "    '''\n",
    "    # La columna onpromotion se cargó como object, ya que hay que arreglar los NA. \n",
    "    # Sustituimos los NA por False (\"sin promoción\"), y convertimos la columna en tipo bool.\n",
    "    data.onpromotion.fillna(False, inplace=True)\n",
    "    data.onpromotion = data.onpromotion.map({'False': False, 'True': True})\n",
    "    data.onpromotion = data.onpromotion.astype(bool)\n",
    "    \n",
    "    # Usamos `np.clip` para cambiar los valores negativos (debidos a devoluciones) por un 0, \n",
    "    # de forma que el argumento mínimo de log1p sea 1 y su resultado mínimo sea 0.\n",
    "    data.unit_sales = np.log1p(np.clip(data.unit_sales, 0, None))\n",
    "    \n",
    "    # Usamos la función add_datepart con el campo date.\n",
    "    add_datepart(data, 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset_in_chunks():\n",
    "    '''\n",
    "    Función que carga y preprocesa los datos usando chunks\n",
    "    '''\n",
    "    # Leer datos. Cargaremos el dataset especificando el nº de filas por chunk en `chunksize`,\n",
    "    # dado que tendremos problemas de memoria si trabajamos con el dataset completo.\n",
    "    file_reader = pd.read_csv('data/train.csv', parse_dates = ['date'], dtype = types, \n",
    "                     infer_datetime_format = True, chunksize=10000000)\n",
    "\n",
    "    chunk_list = [] \n",
    "\n",
    "    for chunk in file_reader:\n",
    "\n",
    "        # Preprocesado del chunk\n",
    "        preprocess_data(chunk)\n",
    "\n",
    "        # Agregamos el chunk a la lista\n",
    "        chunk_list.append(chunk)\n",
    "\n",
    "    # concat the list into dataframe \n",
    "    return pd.concat(chunk_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(file_path):\n",
    "    '''\n",
    "    Función que carga y preprocesa los datos\n",
    "    '''\n",
    "    # Leer datos de un fichero original\n",
    "    df_sample = pd.read_csv(file_path, parse_dates = ['date'], dtype = types, \n",
    "                            infer_datetime_format = True)\n",
    "\n",
    "    # Preprocesado\n",
    "    preprocess_data(df_sample)\n",
    "    \n",
    "    return df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación ejecutamos lo necesario para seguir la estrategia elegida. Primero creamos un dataset con las últimas N filas del original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 data/train.csv > data/train_sample.csv\n",
    "!tail -10000000 data/train.csv >> data/train_sample.csv\n",
    "#!cat data/train_sample.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = process_dataset('data/train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.92 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>item_nbr</th>\n",
       "      <th>unit_sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Dayofweek</th>\n",
       "      <th>Dayofyear</th>\n",
       "      <th>Is_month_end</th>\n",
       "      <th>Is_month_start</th>\n",
       "      <th>Is_quarter_end</th>\n",
       "      <th>Is_quarter_start</th>\n",
       "      <th>Is_year_end</th>\n",
       "      <th>Is_year_start</th>\n",
       "      <th>Elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8791824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9682005</td>\n",
       "      <td>9666352</td>\n",
       "      <td>9894888</td>\n",
       "      <td>9881806</td>\n",
       "      <td>10000000</td>\n",
       "      <td>10000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.204970e+08</td>\n",
       "      <td>2.833271e+01</td>\n",
       "      <td>1.169230e+06</td>\n",
       "      <td>1.692971e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.444426e+00</td>\n",
       "      <td>2.599360e+01</td>\n",
       "      <td>1.571219e+01</td>\n",
       "      <td>3.048752e+00</td>\n",
       "      <td>1.800040e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498695e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.886751e+06</td>\n",
       "      <td>1.630415e+01</td>\n",
       "      <td>5.861997e+05</td>\n",
       "      <td>8.704344e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.784031e-01</td>\n",
       "      <td>3.916341e+00</td>\n",
       "      <td>8.781373e+00</td>\n",
       "      <td>2.046676e+00</td>\n",
       "      <td>2.730393e+01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.359059e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.154970e+08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.699500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.900000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.330000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.494634e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.179970e+08</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>6.919450e+05</td>\n",
       "      <td>1.098612e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.560000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.496621e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.204970e+08</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>1.209720e+06</td>\n",
       "      <td>1.609438e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.800000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.498694e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.229970e+08</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>1.576316e+06</td>\n",
       "      <td>2.197225e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>2.900000e+01</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.040000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.500768e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.254970e+08</td>\n",
       "      <td>5.400000e+01</td>\n",
       "      <td>2.127114e+06</td>\n",
       "      <td>9.640563e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>3.300000e+01</td>\n",
       "      <td>3.100000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.270000e+02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.502755e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id     store_nbr      item_nbr    unit_sales onpromotion  \\\n",
       "count   1.000000e+07  1.000000e+07  1.000000e+07  1.000000e+07    10000000   \n",
       "unique           NaN           NaN           NaN           NaN           2   \n",
       "top              NaN           NaN           NaN           NaN       False   \n",
       "freq             NaN           NaN           NaN           NaN     8791824   \n",
       "mean    1.204970e+08  2.833271e+01  1.169230e+06  1.692971e+00         NaN   \n",
       "std     2.886751e+06  1.630415e+01  5.861997e+05  8.704344e-01         NaN   \n",
       "min     1.154970e+08  1.000000e+00  9.699500e+04  0.000000e+00         NaN   \n",
       "25%     1.179970e+08  1.300000e+01  6.919450e+05  1.098612e+00         NaN   \n",
       "50%     1.204970e+08  2.900000e+01  1.209720e+06  1.609438e+00         NaN   \n",
       "75%     1.229970e+08  4.400000e+01  1.576316e+06  2.197225e+00         NaN   \n",
       "max     1.254970e+08  5.400000e+01  2.127114e+06  9.640563e+00         NaN   \n",
       "\n",
       "              Year         Month          Week           Day     Dayofweek  \\\n",
       "count   10000000.0  1.000000e+07  1.000000e+07  1.000000e+07  1.000000e+07   \n",
       "unique         NaN           NaN           NaN           NaN           NaN   \n",
       "top            NaN           NaN           NaN           NaN           NaN   \n",
       "freq           NaN           NaN           NaN           NaN           NaN   \n",
       "mean        2017.0  6.444426e+00  2.599360e+01  1.571219e+01  3.048752e+00   \n",
       "std            0.0  9.784031e-01  3.916341e+00  8.781373e+00  2.046676e+00   \n",
       "min         2017.0  5.000000e+00  1.900000e+01  1.000000e+00  0.000000e+00   \n",
       "25%         2017.0  6.000000e+00  2.300000e+01  8.000000e+00  1.000000e+00   \n",
       "50%         2017.0  6.000000e+00  2.600000e+01  1.500000e+01  3.000000e+00   \n",
       "75%         2017.0  7.000000e+00  2.900000e+01  2.300000e+01  5.000000e+00   \n",
       "max         2017.0  8.000000e+00  3.300000e+01  3.100000e+01  6.000000e+00   \n",
       "\n",
       "           Dayofyear Is_month_end Is_month_start Is_quarter_end  \\\n",
       "count   1.000000e+07     10000000       10000000       10000000   \n",
       "unique           NaN            2              2              2   \n",
       "top              NaN        False          False          False   \n",
       "freq             NaN      9682005        9666352        9894888   \n",
       "mean    1.800040e+02          NaN            NaN            NaN   \n",
       "std     2.730393e+01          NaN            NaN            NaN   \n",
       "min     1.330000e+02          NaN            NaN            NaN   \n",
       "25%     1.560000e+02          NaN            NaN            NaN   \n",
       "50%     1.800000e+02          NaN            NaN            NaN   \n",
       "75%     2.040000e+02          NaN            NaN            NaN   \n",
       "max     2.270000e+02          NaN            NaN            NaN   \n",
       "\n",
       "       Is_quarter_start Is_year_end Is_year_start       Elapsed  \n",
       "count          10000000    10000000      10000000  1.000000e+07  \n",
       "unique                2           1             1           NaN  \n",
       "top               False       False         False           NaN  \n",
       "freq            9881806    10000000      10000000           NaN  \n",
       "mean                NaN         NaN           NaN  1.498695e+09  \n",
       "std                 NaN         NaN           NaN  2.359059e+06  \n",
       "min                 NaN         NaN           NaN  1.494634e+09  \n",
       "25%                 NaN         NaN           NaN  1.496621e+09  \n",
       "50%                 NaN         NaN           NaN  1.498694e+09  \n",
       "75%                 NaN         NaN           NaN  1.500768e+09  \n",
       "max                 NaN         NaN           NaN  1.502755e+09  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_all.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos el dataframe en formato feather para no tener que repetir la carga:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 909 ms\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('tmp', exist_ok=True)\n",
    "%time df_all.to_feather('tmp/raw_grocery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Muestras de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000000, 18), (2000000, 18))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_vals(a,n): \n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "n_valid = 2000000  # las mismas muestras que los datasets de test\n",
    "n_trn = len(df_all) - n_valid\n",
    "\n",
    "train, valid = split_vals(df_all, n_trn)\n",
    "\n",
    "train.shape, valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, nas = proc_df(train, 'unit_sales')\n",
    "X_valid, y_valid, _ = proc_df(valid, 'unit_sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y validación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, actuals): \n",
    "    return math.sqrt(((predictions - actuals)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    print('RMSE for training:   ', rmse(m.predict(X_train), y_train))\n",
    "    print('RMSE for validation: ', rmse(m.predict(X_valid), y_valid))\n",
    "    print('R^2 for training:    ', m.score(X_train, y_train))\n",
    "    print('R^2 for validation:  ', m.score(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_rf_samples(1_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos X a un array de Numpy para que cada vez que entrenemos el modelo con distintos parámetros no se haga de forma interna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo y lo entrenamos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE for training:    0.5673802075772398\n",
      "RMSE for validation:  0.6543076402230862\n",
      "R^2 for training:     0.5756541678226083\n",
      "R^2 for validation:   0.4320269405678712\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestRegressor(n_estimators=20, min_samples_leaf=3, n_jobs=-1)\n",
    "%prun m.fit(X_train, y_train)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados obtenidos no son del todo malos; de hecho superan a los obtenidos por Jeremy Howard en el curso de fast.ai. Aún así queda pendiente el intentar trabajar con todo el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Kaggle: Favorita Grocery Sales Forecasting",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
